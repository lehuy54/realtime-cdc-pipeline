# Realtime CDC Pipeline | Data Engineering Project

## ğŸ“‘ Má»¥c lá»¥c
- [Giá»›i thiá»‡u](#-giá»›i-thiá»‡u)  
- [Kiáº¿n trÃºc há»‡ thá»‘ng](#-kiáº¿n-trÃºc-há»‡-thá»‘ng)   
- [HÆ°á»›ng dáº«n cÃ i Ä‘áº·t & cháº¡y](#ï¸-hÆ°á»›ng-dáº«n-cÃ i-Ä‘áº·t--cháº¡y)  
- [Giao diá»‡n quáº£n trá»‹](#-giao-diá»‡n-quáº£n-trá»‹)  

---

## Giá»›i thiá»‡u

 Äá»“ng bá»™ dá»¯ liá»‡u thÆ°á»ng dá»±a vÃ o trigger trong database nhÆ°ng xem ra cÃ¡ch nÃ y sáº½ gÃ¢y táº£i náº·ng lÃªn há»‡ thá»‘ng nguá»“n náº¿u dá»¯ liá»‡u Ä‘á»§ lá»›n, cá»™ng hÆ°á»Ÿng vá»›i viá»‡c khÃ³ quáº£n lÃ­. Vá»›i Change Data Capture, ká»¹ thuáº­t báº¯t sá»± thay Ä‘á»•i cá»§a dá»¯ liá»‡u tá»« log cá»§a database Ä‘áº£m báº£o Ã­t áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u nÄƒng, Ä‘á»“ng thá»i dá»¯ liá»‡u Ä‘Æ°á»£c truyá»n Ä‘i gáº§n nhÆ° thá»i gian thá»±c Ä‘áº¿n cÃ¡c há»‡ thá»‘ng downstream

---

## Kiáº¿n trÃºc há»‡ thá»‘ng

![Kiáº¿n trÃºc há»‡ thá»‘ng](https://github.com/lehuy54/realtime-cdc-pipeline/blob/main/System%20Architecture.png)

- **Data source**: MySQL, giáº£ sá»­ cÃ¡c dá»¯ liá»‡u realtime vá» transaction tá»« há»‡ thá»‘ng OLTP Ä‘áº©y vÃ o  
- **Debezium (Source Connector)**: plugins cá»§a kafka connect Ä‘áº£m nhiá»‡m CDC, Ä‘á»c bin log cá»§a MySQL Ä‘á»ƒ báº¯t cÃ¡c action lÃ m thay Ä‘á»•i dá»¯ liá»‡u nhÆ° **insert, update, delete**, sau Ä‘Ã³ convert thÃ nh Avro format Ä‘á»ƒ publish change event lÃªn topic Kafka
- **Kafka**: Message broker truyá»n dá»¯ liá»‡u. Sá»­ dá»¥ng **KRaft mode** Ä‘á»ƒ tá»± quáº£n lÃ½ metadata. Trong project nÃ y chá»‰ sá»­ dá»¥ng 1 broker, 1 replication. Má»—i topic trong Ä‘Ã¢y sáº½ tÆ°Æ¡ng á»©ng vá»›i má»™t table trong database. Tuy nhiÃªn, do tháº±ng Debezium Ä‘Ã£ convert nÃ³ thÃ nh Avro nÃªn cÃ¡c message chá»‰ bao gá»“m schema ID (sáº½ quyáº¿t Ä‘á»‹nh bÃªn trong Schema Registry) + dá»¯ liá»‡u serialized
- **Schema Registry**: Dá»‹ch vá»¥ trung gian cá»§a Kafka dÃ¹ng Ä‘á»ƒ quáº£n lÃ½ vÃ  lÆ°u trá»¯ schema cho dá»¯ liá»‡u trong topic, á»Ÿ trÆ°á»ng há»£p nÃ y ta config nÃ³ Ä‘ang náº¯m giá»¯ Avro format. NÃ³ giÃºp producer vÃ  consumer thá»‘ng nháº¥t dá»¯ liá»‡u, Ä‘áº£m báº£o compability khi cÃ³ schema thay Ä‘á»•i. NgoÃ i ra giÃºp ta tiáº¿t kiá»‡m bá»™ nhá»› hÆ¡n khi message Ä‘Æ°á»£c báº¯n Ä‘i khÃ´ng pháº£i á»Ÿ dáº¡ng Json  
- **Sink Connector**: Ta sá»­ dá»¥ng trá»±c tiáº¿p plugin Google BigQuery Sink connector cá»§a Confluentinc cung cáº¥p, Ä‘á»ƒ nÃ³ láº¥y dá»¯ liá»‡u tá»« Kafka topic, deserialize theo schema tá»« Schema Registry, sau Ä‘Ã³ load vÃ o BigQuery dataset tÆ°Æ¡ng á»©ng
- **Google BigQuery**: cloud data warehouse, trong ká»‹ch báº£n nÃ y nÃ³ sáº½ nháº­n háº¿t dá»¯ liá»‡u deserialized tá»« tháº±ng sink connector (vÃ¬ tháº¿ nÃªn nÃ³ sáº½ bao gá»“m cÃ¡c cá»™t before after cá»§a dá»¯ liá»‡u - náº¿u nhÆ° Ä‘Ã³ lÃ  action update)

---

## HÆ°á»›ng dáº«n cÃ i Ä‘áº·t & cháº¡y

1. Clone repository:
    ```bash
    git clone https://github.com/lehuy54/realtime-cdc-pipeline.git
    ```
2. Táº£i connectors cáº§n thiáº¿t vÃ  giáº£i nÃ©n vÃ o thÆ° má»¥c `connectors/`

- **Source Connector (MySQL Debezium):**  
  [Táº£i táº¡i Ä‘Ã¢y](https://repo1.maven.org/maven2/io/debezium/debezium-connector-mysql/2.5.4.Final/debezium-connector-mysql-2.5.4.Final-plugin.tar.gz)

- **Sink Connector (Google BigQuery):**  
  [Táº£i táº¡i Ä‘Ã¢y](https://www.confluent.io/hub/wepay/kafka-connect-bigquery)

*LÆ°u Ã½: Sá»­ dá»¥ng báº£n **Self-managed** cho mÃ´i trÆ°á»ng Docker/local.*


3. Táº¡o Service Account trÃªn BigQuery, cáº¥p quyá»n **BigQuery Admin** vÃ  quyá»n **BigQuery Data Editor**. Táº¡o Json key vÃ  táº£i vá» Ä‘áº·t trong root cá»§a src code vÃ  rename nÃ³ thÃ nh 'bigquery-credentials.json' 

4. á»Ÿ GCP Console, vÃ o BigQuery -> Create Dataset -> Ä‘áº·t dataset_id lÃ  "inventory_cdc"

5. VÃ o Cloud overview -> Dashboard -> Ä‘á»ƒ láº¥y Project ID sau Ä‘Ã³ thay thÃ nh project id cá»§a báº¡n trong file 'bigquery-connector.json':
    ```bash
    "project": "your-id-project"
    ```
6. Khá»Ÿi Ä‘á»™ng táº¥t cáº£ cÃ¡c service:
    ```bash
    docker compose up -d
    ```
7. cd vá» root src vÃ  Ä‘Äƒng kÃ­ 2 connectors
    ```bash
    curl -X POST http://localhost:8083/connectors \
        -H "Content-Type: application/json" \
        -d @mysql-connector.json

    ```
    ```bash
    curl -X POST http://localhost:8083/connectors \
        -H "Content-Type: application/json" \
        -d @bigquery-connector.json

    ```
8. CÃ³ thá»ƒ lÃªn kafka-ui táº¡i cá»•ng `localhost:8080` Ä‘á»ƒ kiá»ƒm tra xem cÃ¡c topic Ä‘Ã£ Ä‘Æ°á»£c táº¡o chÆ°a, 
   tÃªn cá»§a cÃ¡c topic sáº½ Ä‘Æ°á»£c Ä‘áº·t tÃªn theo config cá»§a debezium connector: 
   `<topic.prefix>.<database>.<table>`

9. Kiá»ƒm tra dá»¯ liá»‡u trÃªn Google BigQuery:
    ```bash
    SELECT * FROM `YOUR_PROJECT_ID.inventory_cdc.dbserver1_inventory_customers` LIMIT 10;
    ```
10. CÃ³ thá»ƒ cháº¡y scripts python data generator Ä‘á»ƒ mÃ´ phá»ng ká»‹ch báº£n realtime:
    ```bash
    python -m venv venv

    ./venv/Scripts/activate

    pip install mysql-connector-python faker

    python streaming-data.py
    ```
